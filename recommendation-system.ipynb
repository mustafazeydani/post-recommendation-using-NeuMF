{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "ee1b2104-56a7-4b64-aa99-8327f5c73d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Multiply, Concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# from tensorflow.keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "# Set the seed for reproducability\n",
    "seed(42)\n",
    "set_seed(42)\n",
    "\n",
    "# Set the output path for saving the model\n",
    "os.environ['CURRENT_PATH'] = os.getcwd()\n",
    "output_path = os.path.join(os.environ['CURRENT_PATH'], 'output')\n",
    "\n",
    "# visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the datasets\n",
    "posts_df = pd.read_csv('datasets/post_data.csv')\n",
    "views_df = pd.read_csv('datasets/view_data.csv')\n",
    "users_df = pd.read_csv('datasets/user_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470643a",
   "metadata": {},
   "source": [
    "# 2. DATA PRE-PROCESSING\n",
    "## 2.1. Generating Score Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a7ab3f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5eece14ffc13ae660900008b</td>\n",
       "      <td>136781766</td>\n",
       "      <td>01/01/2019 01:30 PM</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5eece14efc13ae660900003c</td>\n",
       "      <td>43094523</td>\n",
       "      <td>01/01/2019 01:33 PM</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5eece14efc13ae6609000025</td>\n",
       "      <td>42428071</td>\n",
       "      <td>01/01/2019 01:43 PM</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5eece14ffc13ae66090001d4</td>\n",
       "      <td>76472880</td>\n",
       "      <td>01/01/2019 01:54 PM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5eece14ffc13ae66090000ac</td>\n",
       "      <td>202721843</td>\n",
       "      <td>01/01/2019 02:00 PM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user_id    post_id           time_stamp  score\n",
       "0  5eece14ffc13ae660900008b  136781766  01/01/2019 01:30 PM      2\n",
       "1  5eece14efc13ae660900003c   43094523  01/01/2019 01:33 PM      2\n",
       "2  5eece14efc13ae6609000025   42428071  01/01/2019 01:43 PM      2\n",
       "3  5eece14ffc13ae66090001d4   76472880  01/01/2019 01:54 PM      1\n",
       "4  5eece14ffc13ae66090000ac  202721843  01/01/2019 02:00 PM      3"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views_df_with_scores = pd.DataFrame(views_df)\n",
    "\n",
    "# Generate random probabilities for 1, 2, and 3\n",
    "probs = np.random.dirichlet(np.ones(3))\n",
    "\n",
    "# Assign probabilities for the scores\n",
    "scores = np.random.choice(\n",
    "    [1, 2, 3],\n",
    "    size=len(views_df),\n",
    "    p=probs\n",
    ")\n",
    "\n",
    "# Add the score column to the dataframe\n",
    "views_df_with_scores['score'] = scores\n",
    "\n",
    "views_df_with_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb194f",
   "metadata": {},
   "source": [
    "## 2.2. Data Cleaning and Transformation for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "3baa7612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>813</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>202</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>195</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>469</td>\n",
       "      <td>418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173</td>\n",
       "      <td>1217</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  post_id  score\n",
       "0      140      813      2\n",
       "1       61      202      2\n",
       "2       38      195      2\n",
       "3      469      418      1\n",
       "4      173     1217      3"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the columns that are not needed and remove the rows with missing title values\n",
    "cleaned_data = views_df_with_scores.drop(['time_stamp'], axis=1)\n",
    "\n",
    "# Drop the duplicates\n",
    "cleaned_data = cleaned_data.drop_duplicates()\n",
    "\n",
    "# Map user_id and post_id to numeric indices\n",
    "cleaned_data[\"user_id\"] = cleaned_data[\"user_id\"].astype(\"category\").cat.codes + 1\n",
    "cleaned_data[\"post_id\"] = cleaned_data[\"post_id\"].astype(\"category\").cat.codes + 1\n",
    "\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "75aaeb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 501 unique users and 6001 unique posts in this data set\n"
     ]
    }
   ],
   "source": [
    "unique_users_num = len(cleaned_data.user_id.unique())\n",
    "unique_posts_num = len(cleaned_data.post_id.unique())\n",
    "\n",
    "print('There are {} unique users and {} unique posts in this data set'.format(unique_users_num, unique_posts_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7c7cde41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 501 distinct users, and the max of user_id is also 501\n",
      "There are 6001 distinct posts, and the max of post_id is also 6001\n"
     ]
    }
   ],
   "source": [
    "users_max_id = cleaned_data.user_id.max()\n",
    "posts_max_id = cleaned_data.post_id.max()\n",
    "\n",
    "print('There are {} distinct users, and the max of user_id is also {}'.format(unique_users_num, users_max_id))\n",
    "print('There are {} distinct posts, and the max of post_id is also {}'.format(unique_posts_num, posts_max_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81826817",
   "metadata": {},
   "source": [
    "## 2.3. Splitting Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "fc0ede24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data set:\n",
      "(56980, 3)\n",
      "shape of test data set:\n",
      "(14245, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(cleaned_data, test_size=0.2, shuffle=True, random_state=99)\n",
    "print('shape of training data set:')\n",
    "print(df_train.shape)\n",
    "print('shape of test data set:')\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5852b0df",
   "metadata": {},
   "source": [
    "# 3. Model Training, Evaluation, and Weights Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "3dfa6e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model training function\n",
    "def train_model(model, optimizer, batch_size, num_epochs, validation_split, input_data, target_data, output_model_name):\n",
    "    # Define a custom metric for Root Mean Squared Error (RMSE)\n",
    "    def compute_rmse(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "\n",
    "    # Compile the model with the specified optimizer and loss function\n",
    "    model.compile(\n",
    "        optimizer=optimizer.lower(),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error', compute_rmse]\n",
    "    )\n",
    "\n",
    "    # Define callbacks for early stopping and model checkpointing\n",
    "    early_stopping = EarlyStopping(monitor='val_compute_rmse', patience=10, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        filepath=os.path.join(output_path, output_model_name),\n",
    "        monitor='val_compute_rmse',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True\n",
    "    )\n",
    "\n",
    "    # Train the model and return the history\n",
    "    history = model.fit(\n",
    "        x=input_data,\n",
    "        y=target_data,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "# Define the model's weights loading function\n",
    "def load_model_weights(model, weights_file_path):\n",
    "    model.load_weights(weights_file_path)\n",
    "    return model\n",
    "\n",
    "# Define the model evaluation function\n",
    "calculate_rmse = lambda true_values, predicted_values: np.sqrt(\n",
    "    np.mean(np.square(np.squeeze(predicted_values) - np.squeeze(true_values)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0921c8ce",
   "metadata": {},
   "source": [
    "# 4. Training and Testing the Generalized Matrix Factorization Model\n",
    "## 4.1. Defining the GMF Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "12007f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gmf_model(num_users, num_posts, latent_dim, user_reg, post_reg):\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    post_input = Input(shape=(1,), dtype='int32', name='post_input')\n",
    "\n",
    "    # Embedding layers\n",
    "    user_embedding = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=latent_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='user_embedding',\n",
    "        embeddings_regularizer=l2(user_reg),\n",
    "        input_length=1\n",
    "    )\n",
    "    post_embedding = Embedding(\n",
    "        input_dim=num_posts + 1,\n",
    "        output_dim=latent_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='post_embedding',\n",
    "        embeddings_regularizer=l2(post_reg),\n",
    "        input_length=1\n",
    "    )\n",
    "\n",
    "    # Flatten embedding vectors\n",
    "    user_latent = Flatten()(user_embedding(user_input))\n",
    "    post_latent = Flatten()(post_embedding(post_input))\n",
    "\n",
    "    # Combine user and post embeddings\n",
    "    interaction_vector = Multiply()([user_latent, post_latent])\n",
    "\n",
    "    # Output layer\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(interaction_vector)\n",
    "\n",
    "    # Create and return the model\n",
    "    model = Model([user_input, post_input], prediction)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e0dc2278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_80\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " post_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)  (None, 1, 10)                5020      ['user_input[0][0]']          \n",
      "                                                                                                  \n",
      " post_embedding (Embedding)  (None, 1, 10)                60020     ['post_input[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_212 (Flatten)       (None, 10)                   0         ['user_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_213 (Flatten)       (None, 10)                   0         ['post_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " multiply_54 (Multiply)      (None, 10)                   0         ['flatten_212[0][0]',         \n",
      "                                                                     'flatten_213[0][0]']         \n",
      "                                                                                                  \n",
      " prediction (Dense)          (None, 1)                    11        ['multiply_54[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 65051 (254.11 KB)\n",
      "Trainable params: 65051 (254.11 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 10\n",
    "user_reg = 0\n",
    "post_reg = 0\n",
    "\n",
    "GMF_model = build_gmf_model(unique_users_num, unique_posts_num, latent_dim, user_reg, post_reg)\n",
    "GMF_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1872b5",
   "metadata": {},
   "source": [
    "## 4.2. Training the GMF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5b1c0408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "668/668 [==============================] - 3s 3ms/step - loss: 3.8202 - mean_squared_error: 3.8202 - compute_rmse: 1.9458 - val_loss: 2.7582 - val_mean_squared_error: 2.7582 - val_compute_rmse: 1.6592\n",
      "Epoch 2/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 1.7230 - mean_squared_error: 1.7230 - compute_rmse: 1.2893 - val_loss: 0.7813 - val_mean_squared_error: 0.7813 - val_compute_rmse: 0.8818\n",
      "Epoch 3/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.4412 - mean_squared_error: 0.4412 - compute_rmse: 0.6596 - val_loss: 0.4155 - val_mean_squared_error: 0.4155 - val_compute_rmse: 0.6426\n",
      "Epoch 4/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.3112 - mean_squared_error: 0.3112 - compute_rmse: 0.5560 - val_loss: 0.4129 - val_mean_squared_error: 0.4129 - val_compute_rmse: 0.6405\n",
      "Epoch 5/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.2603 - mean_squared_error: 0.2603 - compute_rmse: 0.5083 - val_loss: 0.4337 - val_mean_squared_error: 0.4337 - val_compute_rmse: 0.6564\n",
      "Epoch 6/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.2176 - mean_squared_error: 0.2176 - compute_rmse: 0.4644 - val_loss: 0.4697 - val_mean_squared_error: 0.4697 - val_compute_rmse: 0.6831\n",
      "Epoch 7/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.1848 - mean_squared_error: 0.1848 - compute_rmse: 0.4278 - val_loss: 0.5040 - val_mean_squared_error: 0.5040 - val_compute_rmse: 0.7077\n",
      "Epoch 8/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.1606 - mean_squared_error: 0.1606 - compute_rmse: 0.3985 - val_loss: 0.5336 - val_mean_squared_error: 0.5336 - val_compute_rmse: 0.7281\n",
      "Epoch 9/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.1421 - mean_squared_error: 0.1421 - compute_rmse: 0.3746 - val_loss: 0.5615 - val_mean_squared_error: 0.5615 - val_compute_rmse: 0.7468\n",
      "Epoch 10/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.1269 - mean_squared_error: 0.1269 - compute_rmse: 0.3538 - val_loss: 0.5858 - val_mean_squared_error: 0.5858 - val_compute_rmse: 0.7627\n",
      "Epoch 11/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.1145 - mean_squared_error: 0.1145 - compute_rmse: 0.3361 - val_loss: 0.6093 - val_mean_squared_error: 0.6093 - val_compute_rmse: 0.7779\n",
      "Epoch 12/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.1035 - mean_squared_error: 0.1035 - compute_rmse: 0.3191 - val_loss: 0.6306 - val_mean_squared_error: 0.6306 - val_compute_rmse: 0.7913\n",
      "Epoch 13/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.0941 - mean_squared_error: 0.0941 - compute_rmse: 0.3042 - val_loss: 0.6526 - val_mean_squared_error: 0.6526 - val_compute_rmse: 0.8049\n",
      "Epoch 14/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.0858 - mean_squared_error: 0.0858 - compute_rmse: 0.2905 - val_loss: 0.6714 - val_mean_squared_error: 0.6714 - val_compute_rmse: 0.8163\n",
      "Epoch 14: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "validation_split = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(GMF_model, 'adam', batch_size, num_epochs, validation_split, \n",
    "                      input_data=[df_train.user_id.values, df_train.post_id.values],\n",
    "                      target_data=df_train.score.values,\n",
    "                        output_model_name='best_gmf_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d5113",
   "metadata": {},
   "source": [
    "## 4.3. Loading the Trained GMF Model and Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f7c9db2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/446 [==============================] - 1s 1ms/step\n",
      "The out-of-sample RMSE of rating predictions is 0.641\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained GMF model with the best weights\n",
    "gmf_model = build_gmf_model(unique_users_num, unique_posts_num, latent_dim, user_reg, post_reg)\n",
    "gmf_model = load_model_weights(gmf_model, os.path.join(output_path, 'best_gmf_model.hdf5'))\n",
    "\n",
    "# Generate predictions using the test data\n",
    "predicted_scores = gmf_model.predict([df_test.user_id.values, df_test.post_id.values])\n",
    "\n",
    "# Calculate the RMSE for the predictions\n",
    "rmse_error = calculate_rmse(df_test.score.values, predicted_scores)\n",
    "\n",
    "# Print the RMSE result\n",
    "print('The out-of-sample RMSE of rating predictions is', round(rmse_error, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b25dd",
   "metadata": {},
   "source": [
    "# 5. Training and Testing the Multi-Layer Perceptron Model\n",
    "## 5.1. Defining the MLP Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "72c50f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp_model(num_users, num_posts, layers, reg_layers):\n",
    "    # Ensure the number of layers matches the number of regularization parameters\n",
    "    assert len(layers) == len(reg_layers)\n",
    "    num_layer = len(layers)  # Number of layers in the MLP\n",
    "\n",
    "    # Define input layers for user and post IDs\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    post_input = Input(shape=(1,), dtype='int32', name='post_input')\n",
    "\n",
    "    # Define embedding layers for users and posts\n",
    "    user_embedding = Embedding(\n",
    "        input_dim=num_users + 1,           \n",
    "        output_dim=layers[0] // 2,        \n",
    "        embeddings_initializer='uniform', \n",
    "        name='user_embedding',           \n",
    "        embeddings_regularizer=l2(reg_layers[0]),  \n",
    "        input_length=1)                   \n",
    "    \n",
    "    post_embedding = Embedding(\n",
    "        input_dim=num_posts + 1,         \n",
    "        output_dim=layers[0] // 2,       \n",
    "        embeddings_initializer='uniform', \n",
    "        name='post_embedding',           \n",
    "        embeddings_regularizer=l2(reg_layers[0]), \n",
    "        input_length=1)                   \n",
    "\n",
    "    # Flatten the embeddings to prepare for concatenation\n",
    "    user_latent = Flatten()(user_embedding(user_input))  \n",
    "    post_latent = Flatten()(post_embedding(post_input))  \n",
    "\n",
    "    # Concatenate the user and item embedding vectors\n",
    "    vector = Concatenate(axis=-1)([user_latent, post_latent])\n",
    "\n",
    "    # Add fully connected (dense) layers\n",
    "    for idx in range(1, num_layer): \n",
    "        layer = Dense(\n",
    "            units=layers[idx],                   \n",
    "            activation='relu',                   \n",
    "            kernel_initializer='glorot_uniform',\n",
    "            kernel_regularizer=l2(reg_layers[idx]), \n",
    "            name=f'layer{idx}')                 \n",
    "        vector = layer(vector) \n",
    "    \n",
    "    # Add the final prediction layer with a single output\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(vector)\n",
    "\n",
    "    # Create the model with user and post inputs and prediction as the output\n",
    "    model = Model([user_input, post_input], prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "71e8f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_82\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " post_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)  (None, 1, 32)                16064     ['user_input[0][0]']          \n",
      "                                                                                                  \n",
      " post_embedding (Embedding)  (None, 1, 32)                192064    ['post_input[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_216 (Flatten)       (None, 32)                   0         ['user_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_217 (Flatten)       (None, 32)                   0         ['post_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_78 (Concatenat  (None, 64)                   0         ['flatten_216[0][0]',         \n",
      " e)                                                                  'flatten_217[0][0]']         \n",
      "                                                                                                  \n",
      " layer1 (Dense)              (None, 32)                   2080      ['concatenate_78[0][0]']      \n",
      "                                                                                                  \n",
      " layer2 (Dense)              (None, 16)                   528       ['layer1[0][0]']              \n",
      "                                                                                                  \n",
      " layer3 (Dense)              (None, 8)                    136       ['layer2[0][0]']              \n",
      "                                                                                                  \n",
      " prediction (Dense)          (None, 1)                    9         ['layer3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 210881 (823.75 KB)\n",
      "Trainable params: 210881 (823.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers = [64, 32, 16, 8]\n",
    "reg_layers = [0, 0, 0, 0]\n",
    "\n",
    "MLP_model = build_mlp_model(unique_users_num, unique_posts_num, layers, reg_layers)\n",
    "MLP_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7850c",
   "metadata": {},
   "source": [
    "## 5.2. Training the MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "aa2de712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.6943 - mean_squared_error: 0.6943 - compute_rmse: 0.7315 - val_loss: 0.3512 - val_mean_squared_error: 0.3512 - val_compute_rmse: 0.5908\n",
      "Epoch 2/100\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.3370 - mean_squared_error: 0.3370 - compute_rmse: 0.5785 - val_loss: 0.3506 - val_mean_squared_error: 0.3506 - val_compute_rmse: 0.5902\n",
      "Epoch 3/100\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.3202 - mean_squared_error: 0.3202 - compute_rmse: 0.5639 - val_loss: 0.3578 - val_mean_squared_error: 0.3578 - val_compute_rmse: 0.5962\n",
      "Epoch 4/100\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.3011 - mean_squared_error: 0.3011 - compute_rmse: 0.5469 - val_loss: 0.3742 - val_mean_squared_error: 0.3742 - val_compute_rmse: 0.6097\n",
      "Epoch 5/100\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.2735 - mean_squared_error: 0.2735 - compute_rmse: 0.5208 - val_loss: 0.4031 - val_mean_squared_error: 0.4031 - val_compute_rmse: 0.6329\n",
      "Epoch 6/100\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.2405 - mean_squared_error: 0.2405 - compute_rmse: 0.4883 - val_loss: 0.4338 - val_mean_squared_error: 0.4338 - val_compute_rmse: 0.6563\n",
      "Epoch 7/100\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.2077 - mean_squared_error: 0.2077 - compute_rmse: 0.4534 - val_loss: 0.4594 - val_mean_squared_error: 0.4594 - val_compute_rmse: 0.6754\n",
      "Epoch 8/100\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.1753 - mean_squared_error: 0.1753 - compute_rmse: 0.4161 - val_loss: 0.4942 - val_mean_squared_error: 0.4942 - val_compute_rmse: 0.7004\n",
      "Epoch 9/100\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.1449 - mean_squared_error: 0.1449 - compute_rmse: 0.3781 - val_loss: 0.5183 - val_mean_squared_error: 0.5183 - val_compute_rmse: 0.7173\n",
      "Epoch 10/100\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.1199 - mean_squared_error: 0.1199 - compute_rmse: 0.3436 - val_loss: 0.5389 - val_mean_squared_error: 0.5389 - val_compute_rmse: 0.7316\n",
      "Epoch 11/100\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0992 - mean_squared_error: 0.0992 - compute_rmse: 0.3125 - val_loss: 0.5808 - val_mean_squared_error: 0.5808 - val_compute_rmse: 0.7593\n",
      "Epoch 12/100\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.0824 - mean_squared_error: 0.0824 - compute_rmse: 0.2845 - val_loss: 0.5916 - val_mean_squared_error: 0.5916 - val_compute_rmse: 0.7664\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "validation_split = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(MLP_model, 'adam', batch_size, num_epochs, validation_split, \n",
    "                      input_data=[df_train.user_id.values, df_train.post_id.values],\n",
    "                      target_data=df_train.score.values,\n",
    "                        output_model_name='best_mlp_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e513e2fc",
   "metadata": {},
   "source": [
    "## 5.3. Loading the Trained MLP Model and Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "966447b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/446 [==============================] - 1s 1ms/step\n",
      "The out-of-sample RMSE of rating predictions is 0.589\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained MLP model with the best weights\n",
    "mlp_model = build_mlp_model(unique_users_num, unique_posts_num, layers, reg_layers)\n",
    "mlp_model = load_model_weights(mlp_model, os.path.join(output_path, 'best_mlp_model.hdf5'))\n",
    "\n",
    "# Generate predictions using the test data\n",
    "predicted_scores = mlp_model.predict([df_test.user_id.values, df_test.post_id.values])\n",
    "\n",
    "# Calculate the RMSE for the predictions\n",
    "rmse_error = calculate_rmse(df_test.score.values, predicted_scores)\n",
    "\n",
    "# Print the RMSE result\n",
    "print('The out-of-sample RMSE of rating predictions is', round(rmse_error, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb02f0e",
   "metadata": {},
   "source": [
    "# 6. Training and Testing the Neural Matrix Factorization Model\n",
    "## 6.1. Defining the NeuMF Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "42b87a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neumf_model(num_users, num_posts, MF_dim, MF_reg, MLP_layers, MLP_regs):\n",
    "    # Ensure the number of layers matches the number of regularization parameters\n",
    "    assert len(MLP_layers) == len(MLP_regs)\n",
    "    num_MLP_layer = len(MLP_layers) # Number of layers in the MLP\n",
    "\n",
    "    # Define input layers for user and post IDs\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    post_input = Input(shape=(1,), dtype='int32', name='post_input')\n",
    "\n",
    "    # Embedding layers for MF\n",
    "    mf_user_embedding = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=MF_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mf_user_embedding',\n",
    "        embeddings_regularizer=l2(MF_reg[0]),\n",
    "        input_length=1)\n",
    "    mf_post_embedding = Embedding(\n",
    "        input_dim=num_posts + 1,\n",
    "        output_dim=MF_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mf_post_embedding',\n",
    "        embeddings_regularizer=l2(MF_reg[1]),\n",
    "        input_length=1)\n",
    "    \n",
    "    # Embedding layers for MLP\n",
    "    mlp_user_embedding = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=MLP_layers[0] // 2,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mlp_user_embedding',\n",
    "        embeddings_regularizer=l2(MLP_regs[0]),\n",
    "        input_length=1)\n",
    "    mlp_post_embedding = Embedding(\n",
    "        input_dim=num_posts + 1,\n",
    "        output_dim=MLP_layers[0] // 2,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mlp_post_embedding',\n",
    "        embeddings_regularizer=l2(MLP_regs[0]),\n",
    "        input_length=1) \n",
    "    \n",
    "    # Flatten the embeddings to prepare for concatenation\n",
    "    mf_user_latent = Flatten()(mf_user_embedding(user_input))\n",
    "    mf_post_latent = Flatten()(mf_post_embedding(post_input))\n",
    "    mf_vector = Multiply()([mf_user_latent, mf_post_latent])\n",
    "\n",
    "    # Flatten the embeddings to prepare for concatenation\n",
    "    mlp_user_latent = Flatten()(mlp_user_embedding(user_input))\n",
    "    mlp_post_latent = Flatten()(mlp_post_embedding(post_input))\n",
    "    mlp_vector = Concatenate(axis=-1)([mlp_user_latent, mlp_post_latent])\n",
    "    \n",
    "    # Concatenate the two latent vectors\n",
    "    # Add fully connected (dense) layers\n",
    "    for idx in range(1, num_MLP_layer):\n",
    "        layer = Dense(\n",
    "            units=MLP_layers[idx],\n",
    "            activation='relu',\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            kernel_regularizer=l2(MLP_regs[idx]),\n",
    "            name = 'layer%d' %idx)\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "    \n",
    "    predict_vector = Concatenate(axis=-1)([mf_vector, mlp_vector])\n",
    "\n",
    "    # Concatenate the two latent vectors\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(predict_vector)\n",
    "    \n",
    "    # Create the model with user and post inputs and prediction as the output\n",
    "    model = Model([user_input, post_input], prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f97ea9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_84\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " post_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " mlp_user_embedding (Embedd  (None, 1, 32)                16064     ['user_input[0][0]']          \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " mlp_post_embedding (Embedd  (None, 1, 32)                192064    ['post_input[0][0]']          \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " flatten_222 (Flatten)       (None, 32)                   0         ['mlp_user_embedding[0][0]']  \n",
      "                                                                                                  \n",
      " flatten_223 (Flatten)       (None, 32)                   0         ['mlp_post_embedding[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_80 (Concatenat  (None, 64)                   0         ['flatten_222[0][0]',         \n",
      " e)                                                                  'flatten_223[0][0]']         \n",
      "                                                                                                  \n",
      " mf_user_embedding (Embeddi  (None, 1, 10)                5020      ['user_input[0][0]']          \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " mf_post_embedding (Embeddi  (None, 1, 10)                60020     ['post_input[0][0]']          \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " layer1 (Dense)              (None, 32)                   2080      ['concatenate_80[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_220 (Flatten)       (None, 10)                   0         ['mf_user_embedding[0][0]']   \n",
      "                                                                                                  \n",
      " flatten_221 (Flatten)       (None, 10)                   0         ['mf_post_embedding[0][0]']   \n",
      "                                                                                                  \n",
      " layer2 (Dense)              (None, 16)                   528       ['layer1[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_56 (Multiply)      (None, 10)                   0         ['flatten_220[0][0]',         \n",
      "                                                                     'flatten_221[0][0]']         \n",
      "                                                                                                  \n",
      " layer3 (Dense)              (None, 8)                    136       ['layer2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_81 (Concatenat  (None, 18)                   0         ['multiply_56[0][0]',         \n",
      " e)                                                                  'layer3[0][0]']              \n",
      "                                                                                                  \n",
      " prediction (Dense)          (None, 1)                    19        ['concatenate_81[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 275931 (1.05 MB)\n",
      "Trainable params: 275931 (1.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MF_dim = 10\n",
    "MF_reg = (0, 0)\n",
    "MLP_layers = [64, 32, 16, 8]\n",
    "MLP_regs = [0, 0, 0, 0]\n",
    "\n",
    "NeuMF_model = build_neumf_model(\n",
    "    num_users=unique_users_num,\n",
    "    num_posts=unique_posts_num,\n",
    "    MF_dim=MF_dim,\n",
    "    MF_reg=MF_reg,\n",
    "    MLP_layers=MLP_layers,\n",
    "    MLP_regs=MLP_regs\n",
    ")\n",
    "NeuMF_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6b9c3",
   "metadata": {},
   "source": [
    "## 6.2. Training the NeuMF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "bb17b720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "668/668 [==============================] - 5s 5ms/step - loss: 0.6565 - mean_squared_error: 0.6565 - compute_rmse: 0.7170 - val_loss: 0.3486 - val_mean_squared_error: 0.3486 - val_compute_rmse: 0.5886\n",
      "Epoch 2/100\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.3316 - mean_squared_error: 0.3316 - compute_rmse: 0.5739 - val_loss: 0.3520 - val_mean_squared_error: 0.3520 - val_compute_rmse: 0.5914\n",
      "Epoch 3/100\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.2698 - mean_squared_error: 0.2698 - compute_rmse: 0.5175 - val_loss: 0.3730 - val_mean_squared_error: 0.3730 - val_compute_rmse: 0.6089\n",
      "Epoch 4/100\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.1678 - mean_squared_error: 0.1678 - compute_rmse: 0.4078 - val_loss: 0.4261 - val_mean_squared_error: 0.4261 - val_compute_rmse: 0.6507\n",
      "Epoch 5/100\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.1038 - mean_squared_error: 0.1038 - compute_rmse: 0.3202 - val_loss: 0.4726 - val_mean_squared_error: 0.4726 - val_compute_rmse: 0.6852\n",
      "Epoch 6/100\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.0685 - mean_squared_error: 0.0685 - compute_rmse: 0.2591 - val_loss: 0.4990 - val_mean_squared_error: 0.4990 - val_compute_rmse: 0.7041\n",
      "Epoch 7/100\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.0478 - mean_squared_error: 0.0478 - compute_rmse: 0.2161 - val_loss: 0.5166 - val_mean_squared_error: 0.5166 - val_compute_rmse: 0.7164\n",
      "Epoch 8/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - compute_rmse: 0.1852 - val_loss: 0.5361 - val_mean_squared_error: 0.5361 - val_compute_rmse: 0.7298\n",
      "Epoch 9/100\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.0284 - mean_squared_error: 0.0284 - compute_rmse: 0.1657 - val_loss: 0.5464 - val_mean_squared_error: 0.5464 - val_compute_rmse: 0.7367\n",
      "Epoch 10/100\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.0242 - mean_squared_error: 0.0242 - compute_rmse: 0.1527 - val_loss: 0.5530 - val_mean_squared_error: 0.5530 - val_compute_rmse: 0.7412\n",
      "Epoch 11/100\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.0212 - mean_squared_error: 0.0212 - compute_rmse: 0.1426 - val_loss: 0.5613 - val_mean_squared_error: 0.5613 - val_compute_rmse: 0.7468\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "validation_split = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(NeuMF_model, 'adam', batch_size, num_epochs, validation_split, \n",
    "                        input_data=[df_train.user_id.values, df_train.post_id.values],\n",
    "                        target_data=df_train.score.values,\n",
    "                        output_model_name='best_neumf_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d61830c",
   "metadata": {},
   "source": [
    "## 6.3. Loading the Trained NeuMF Model and Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "946c5dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/446 [==============================] - 1s 1ms/step\n",
      "The out-of-sample RMSE of rating predictions is 0.5868\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained NeuMF model with the best weights\n",
    "neumf_model = build_neumf_model(\n",
    "    num_users=users_max_id,\n",
    "    num_posts=posts_max_id,\n",
    "    MF_dim=MF_dim,\n",
    "    MF_reg=MF_reg,\n",
    "    MLP_layers=MLP_layers,\n",
    "    MLP_regs=MLP_regs\n",
    ")\n",
    "neumf_model = load_model_weights(neumf_model, os.path.join(output_path, 'best_neumf_model.hdf5'))\n",
    "\n",
    "# Generate predictions using the test data\n",
    "predicted_scores = neumf_model.predict([df_test.user_id.values, df_test.post_id.values])\n",
    "\n",
    "# Calculate the RMSE for the predictions\n",
    "rmse_error = calculate_rmse(df_test.score.values, predicted_scores)\n",
    "\n",
    "# Print the RMSE result\n",
    "print('The out-of-sample RMSE of rating predictions is', round(rmse_error, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
