{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee1b2104-56a7-4b64-aa99-8327f5c73d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Multiply, Concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# from tensorflow.keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Set the output path for saving the model\n",
    "os.environ['CURRENT_PATH'] = os.getcwd()\n",
    "output_path = os.path.join(os.environ['CURRENT_PATH'], 'output')\n",
    "\n",
    "# visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the datasets\n",
    "posts_df = pd.read_csv('datasets/post_data.csv')\n",
    "views_df = pd.read_csv('datasets/view_data.csv')\n",
    "users_df = pd.read_csv('datasets/user_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470643a",
   "metadata": {},
   "source": [
    "# 2. DATA PRE-PROCESSING\n",
    "## 2.1. Generating Score Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7ab3f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5eece14ffc13ae660900008b</td>\n",
       "      <td>136781766</td>\n",
       "      <td>01/01/2019 01:30 PM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5eece14efc13ae660900003c</td>\n",
       "      <td>43094523</td>\n",
       "      <td>01/01/2019 01:33 PM</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5eece14efc13ae6609000025</td>\n",
       "      <td>42428071</td>\n",
       "      <td>01/01/2019 01:43 PM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5eece14ffc13ae66090001d4</td>\n",
       "      <td>76472880</td>\n",
       "      <td>01/01/2019 01:54 PM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5eece14ffc13ae66090000ac</td>\n",
       "      <td>202721843</td>\n",
       "      <td>01/01/2019 02:00 PM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user_id    post_id           time_stamp  score\n",
       "0  5eece14ffc13ae660900008b  136781766  01/01/2019 01:30 PM      3\n",
       "1  5eece14efc13ae660900003c   43094523  01/01/2019 01:33 PM      2\n",
       "2  5eece14efc13ae6609000025   42428071  01/01/2019 01:43 PM      3\n",
       "3  5eece14ffc13ae66090001d4   76472880  01/01/2019 01:54 PM      3\n",
       "4  5eece14ffc13ae66090000ac  202721843  01/01/2019 02:00 PM      3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views_df_with_scores = pd.DataFrame(views_df)\n",
    "\n",
    "# Generate random probabilities for 1, 2, and 3\n",
    "probs = np.random.dirichlet(np.ones(3))\n",
    "\n",
    "# Assign probabilities for the scores\n",
    "scores = np.random.choice(\n",
    "    [1, 2, 3],\n",
    "    size=len(views_df),\n",
    "    p=probs\n",
    ")\n",
    "\n",
    "# Add the score column to the dataframe\n",
    "views_df_with_scores['score'] = scores\n",
    "\n",
    "views_df_with_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb194f",
   "metadata": {},
   "source": [
    "## 2.2. Data Cleaning and Transformation for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3baa7612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>813</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>202</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>195</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>469</td>\n",
       "      <td>418</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173</td>\n",
       "      <td>1217</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  post_id  score\n",
       "0      140      813      3\n",
       "1       61      202      2\n",
       "2       38      195      3\n",
       "3      469      418      3\n",
       "4      173     1217      3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the columns that are not needed and remove the rows with missing title values\n",
    "cleaned_data = views_df_with_scores.drop(['time_stamp'], axis=1)\n",
    "\n",
    "# Drop the duplicates\n",
    "cleaned_data = cleaned_data.drop_duplicates()\n",
    "\n",
    "# Map user_id and post_id to numeric indices\n",
    "cleaned_data[\"user_id\"] = cleaned_data[\"user_id\"].astype(\"category\").cat.codes + 1\n",
    "cleaned_data[\"post_id\"] = cleaned_data[\"post_id\"].astype(\"category\").cat.codes + 1\n",
    "\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75aaeb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 501 unique users and 6001 unique posts in this data set\n"
     ]
    }
   ],
   "source": [
    "unique_users_num = len(cleaned_data.user_id.unique())\n",
    "unique_posts_num = len(cleaned_data.post_id.unique())\n",
    "\n",
    "print('There are {} unique users and {} unique posts in this data set'.format(unique_users_num, unique_posts_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c7cde41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 501 distinct users, and the max of user_id is also 501\n",
      "There are 6001 distinct posts, and the max of post_id is also 6001\n"
     ]
    }
   ],
   "source": [
    "users_max_id = cleaned_data.user_id.max()\n",
    "posts_max_id = cleaned_data.post_id.max()\n",
    "\n",
    "print('There are {} distinct users, and the max of user_id is also {}'.format(unique_users_num, users_max_id))\n",
    "print('There are {} distinct posts, and the max of post_id is also {}'.format(unique_posts_num, posts_max_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81826817",
   "metadata": {},
   "source": [
    "## 2.3. Splitting Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc0ede24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data set:\n",
      "(56946, 3)\n",
      "shape of test data set:\n",
      "(14237, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(cleaned_data, test_size=0.2, shuffle=True, random_state=99)\n",
    "print('shape of training data set:')\n",
    "print(df_train.shape)\n",
    "print('shape of test data set:')\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5852b0df",
   "metadata": {},
   "source": [
    "# 3. Model Training, Evaluation, and Weights Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dfa6e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model training function\n",
    "def train_model(model, optimizer, batch_size, num_epochs, validation_split, input_data, target_data, output_model_name):\n",
    "    # Define a custom metric for Root Mean Squared Error (RMSE)\n",
    "    def compute_rmse(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "\n",
    "    # Compile the model with the specified optimizer and loss function\n",
    "    model.compile(\n",
    "        optimizer=optimizer.lower(),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error', compute_rmse]\n",
    "    )\n",
    "\n",
    "    # Define callbacks for early stopping and model checkpointing\n",
    "    early_stopping = EarlyStopping(monitor='val_compute_rmse', patience=10, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        filepath=os.path.join(output_path, output_model_name),\n",
    "        monitor='val_compute_rmse',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True\n",
    "    )\n",
    "\n",
    "    # Train the model and return the history\n",
    "    history = model.fit(\n",
    "        x=input_data,\n",
    "        y=target_data,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "# Define the model's weights loading function\n",
    "def load_model_weights(model, weights_file_path):\n",
    "    model.load_weights(weights_file_path)\n",
    "    return model\n",
    "\n",
    "# Define the model evaluation function\n",
    "calculate_rmse = lambda true_values, predicted_values: np.sqrt(\n",
    "    np.mean(np.square(np.squeeze(predicted_values) - np.squeeze(true_values)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0921c8ce",
   "metadata": {},
   "source": [
    "# 4. Training and Testing the Generalized Matrix Factorization Model\n",
    "## 4.1. Defining the GMF Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12007f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gmf_model(num_users, num_posts, latent_dim, user_reg, post_reg):\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    post_input = Input(shape=(1,), dtype='int32', name='post_input')\n",
    "\n",
    "    # Embedding layers\n",
    "    user_embedding = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=latent_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='user_embedding',\n",
    "        embeddings_regularizer=l2(user_reg),\n",
    "        input_length=1\n",
    "    )\n",
    "    post_embedding = Embedding(\n",
    "        input_dim=num_posts + 1,\n",
    "        output_dim=latent_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='post_embedding',\n",
    "        embeddings_regularizer=l2(post_reg),\n",
    "        input_length=1\n",
    "    )\n",
    "\n",
    "    # Flatten embedding vectors\n",
    "    user_latent = Flatten()(user_embedding(user_input))\n",
    "    post_latent = Flatten()(post_embedding(post_input))\n",
    "\n",
    "    # Combine user and post embeddings\n",
    "    interaction_vector = Multiply()([user_latent, post_latent])\n",
    "\n",
    "    # Output layer\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(interaction_vector)\n",
    "\n",
    "    # Create and return the model\n",
    "    model = Model([user_input, post_input], prediction)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0dc2278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " post_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)  (None, 1, 8)                 4016      ['user_input[0][0]']          \n",
      "                                                                                                  \n",
      " post_embedding (Embedding)  (None, 1, 8)                 48016     ['post_input[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_16 (Flatten)        (None, 8)                    0         ['user_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_17 (Flatten)        (None, 8)                    0         ['post_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)       (None, 8)                    0         ['flatten_16[0][0]',          \n",
      "                                                                     'flatten_17[0][0]']          \n",
      "                                                                                                  \n",
      " prediction (Dense)          (None, 1)                    9         ['multiply_4[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 52041 (203.29 KB)\n",
      "Trainable params: 52041 (203.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 8\n",
    "user_reg = 0.01\n",
    "post_reg = 0.01\n",
    "\n",
    "GMF_model = build_gmf_model(users_max_id, posts_max_id, latent_dim, user_reg, post_reg)\n",
    "GMF_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1872b5",
   "metadata": {},
   "source": [
    "## 4.2. Training the GMF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b1c0408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "668/668 [==============================] - 3s 3ms/step - loss: 5.5725 - mean_squared_error: 5.5633 - compute_rmse: 2.3511 - val_loss: 4.2856 - val_mean_squared_error: 4.2856 - val_compute_rmse: 2.0694\n",
      "Epoch 2/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 3.2686 - mean_squared_error: 3.2686 - compute_rmse: 1.8009 - val_loss: 2.4584 - val_mean_squared_error: 2.4584 - val_compute_rmse: 1.5671\n",
      "Epoch 3/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 1.8452 - mean_squared_error: 1.8452 - compute_rmse: 1.3526 - val_loss: 1.3743 - val_mean_squared_error: 1.3743 - val_compute_rmse: 1.1717\n",
      "Epoch 4/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 1.0490 - mean_squared_error: 1.0490 - compute_rmse: 1.0205 - val_loss: 0.8106 - val_mean_squared_error: 0.8106 - val_compute_rmse: 0.8999\n",
      "Epoch 5/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.6718 - mean_squared_error: 0.6718 - compute_rmse: 0.8181 - val_loss: 0.5737 - val_mean_squared_error: 0.5737 - val_compute_rmse: 0.7565\n",
      "Epoch 6/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.5339 - mean_squared_error: 0.5339 - compute_rmse: 0.7289 - val_loss: 0.5009 - val_mean_squared_error: 0.5009 - val_compute_rmse: 0.7056\n",
      "Epoch 7/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.5000 - mean_squared_error: 0.5000 - compute_rmse: 0.7048 - val_loss: 0.4870 - val_mean_squared_error: 0.4870 - val_compute_rmse: 0.6949\n",
      "Epoch 8/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.4954 - mean_squared_error: 0.4954 - compute_rmse: 0.7012 - val_loss: 0.4854 - val_mean_squared_error: 0.4854 - val_compute_rmse: 0.6935\n",
      "Epoch 9/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7006 - val_loss: 0.4852 - val_mean_squared_error: 0.4852 - val_compute_rmse: 0.6932\n",
      "Epoch 10/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7005 - val_loss: 0.4852 - val_mean_squared_error: 0.4852 - val_compute_rmse: 0.6932\n",
      "Epoch 11/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7003 - val_loss: 0.4852 - val_mean_squared_error: 0.4852 - val_compute_rmse: 0.6932\n",
      "Epoch 12/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7006 - val_loss: 0.4854 - val_mean_squared_error: 0.4854 - val_compute_rmse: 0.6935\n",
      "Epoch 13/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7009 - val_loss: 0.4852 - val_mean_squared_error: 0.4852 - val_compute_rmse: 0.6933\n",
      "Epoch 14/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7010 - val_loss: 0.4855 - val_mean_squared_error: 0.4855 - val_compute_rmse: 0.6935\n",
      "Epoch 15/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7004 - val_loss: 0.4855 - val_mean_squared_error: 0.4855 - val_compute_rmse: 0.6935\n",
      "Epoch 16/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7007 - val_loss: 0.4854 - val_mean_squared_error: 0.4854 - val_compute_rmse: 0.6934\n",
      "Epoch 17/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.4952 - mean_squared_error: 0.4952 - compute_rmse: 0.7002 - val_loss: 0.4851 - val_mean_squared_error: 0.4851 - val_compute_rmse: 0.6930\n",
      "Epoch 18/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7006 - val_loss: 0.4854 - val_mean_squared_error: 0.4854 - val_compute_rmse: 0.6935\n",
      "Epoch 19/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7007 - val_loss: 0.4851 - val_mean_squared_error: 0.4851 - val_compute_rmse: 0.6932\n",
      "Epoch 20/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7005 - val_loss: 0.4852 - val_mean_squared_error: 0.4852 - val_compute_rmse: 0.6933\n",
      "Epoch 21/100\n",
      "668/668 [==============================] - 1s 2ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7006 - val_loss: 0.4852 - val_mean_squared_error: 0.4852 - val_compute_rmse: 0.6932\n",
      "Epoch 22/100\n",
      "668/668 [==============================] - 1s 2ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7005 - val_loss: 0.4852 - val_mean_squared_error: 0.4852 - val_compute_rmse: 0.6933\n",
      "Epoch 23/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7004 - val_loss: 0.4853 - val_mean_squared_error: 0.4853 - val_compute_rmse: 0.6933\n",
      "Epoch 24/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7008 - val_loss: 0.4852 - val_mean_squared_error: 0.4852 - val_compute_rmse: 0.6933\n",
      "Epoch 25/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7006 - val_loss: 0.4851 - val_mean_squared_error: 0.4851 - val_compute_rmse: 0.6931\n",
      "Epoch 26/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7009 - val_loss: 0.4854 - val_mean_squared_error: 0.4854 - val_compute_rmse: 0.6934\n",
      "Epoch 27/100\n",
      "668/668 [==============================] - 2s 2ms/step - loss: 0.4951 - mean_squared_error: 0.4951 - compute_rmse: 0.7007 - val_loss: 0.4852 - val_mean_squared_error: 0.4852 - val_compute_rmse: 0.6932\n",
      "Epoch 27: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "validation_split = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(GMF_model, 'adam', batch_size, num_epochs, validation_split, \n",
    "                      input_data=[df_train.user_id.values, df_train.post_id.values],\n",
    "                      target_data=df_train.score.values,\n",
    "                        output_model_name='best_gmf_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d5113",
   "metadata": {},
   "source": [
    "## 4.3. Loading the Trained GMF Model and Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7c9db2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 1s 1ms/step\n",
      "The out-of-sample RMSE of rating predictions is 0.7025\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained GMF model with the best weights\n",
    "gmf_model = build_gmf_model(users_max_id, posts_max_id, latent_dim, user_reg, post_reg)\n",
    "gmf_model = load_model_weights(gmf_model, os.path.join(output_path, 'best_gmf_model.hdf5'))\n",
    "\n",
    "# Generate predictions using the test data\n",
    "predicted_scores = gmf_model.predict([df_test.user_id.values, df_test.post_id.values])\n",
    "\n",
    "# Calculate the RMSE for the predictions\n",
    "rmse_error = calculate_rmse(df_test.score.values, predicted_scores)\n",
    "\n",
    "# Print the RMSE result\n",
    "print('The out-of-sample RMSE of rating predictions is', round(rmse_error, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b25dd",
   "metadata": {},
   "source": [
    "# 5. Training and Testing the Multi-Layer Perceptron Model\n",
    "## 5.1. Defining the MLP Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72c50f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp_model(num_users, num_posts, layers, reg_layers):\n",
    "    # Ensure the number of layers matches the number of regularization parameters\n",
    "    assert len(layers) == len(reg_layers)\n",
    "    num_layer = len(layers)  # Number of layers in the MLP\n",
    "\n",
    "    # Define input layers for user and post IDs\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    post_input = Input(shape=(1,), dtype='int32', name='post_input')\n",
    "\n",
    "    # Define embedding layers for users and posts\n",
    "    user_embedding = Embedding(\n",
    "        input_dim=num_users + 1,           \n",
    "        output_dim=layers[0] // 2,        \n",
    "        embeddings_initializer='uniform', \n",
    "        name='user_embedding',           \n",
    "        embeddings_regularizer=l2(reg_layers[0]),  \n",
    "        input_length=1)                   \n",
    "    \n",
    "    post_embedding = Embedding(\n",
    "        input_dim=num_posts + 1,         \n",
    "        output_dim=layers[0] // 2,       \n",
    "        embeddings_initializer='uniform', \n",
    "        name='post_embedding',           \n",
    "        embeddings_regularizer=l2(reg_layers[0]), \n",
    "        input_length=1)                   \n",
    "\n",
    "    # Flatten the embeddings to prepare for concatenation\n",
    "    user_latent = Flatten()(user_embedding(user_input))  \n",
    "    item_latent = Flatten()(post_embedding(post_input))  \n",
    "\n",
    "    # Concatenate the user and item embedding vectors\n",
    "    vector = Concatenate(axis=-1)([user_latent, item_latent])\n",
    "\n",
    "    # Add fully connected (dense) layers\n",
    "    for idx in range(1, num_layer): \n",
    "        layer = Dense(\n",
    "            units=layers[idx],                   \n",
    "            activation='relu',                   \n",
    "            kernel_initializer='glorot_uniform',\n",
    "            kernel_regularizer=l2(reg_layers[idx]), \n",
    "            name=f'layer{idx}')                 \n",
    "        vector = layer(vector) \n",
    "    \n",
    "    # Add the final prediction layer with a single output\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(vector)\n",
    "\n",
    "    # Create the model with user and post inputs and prediction as the output\n",
    "    model = Model([user_input, post_input], prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71e8f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " post_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)  (None, 1, 32)                16064     ['user_input[0][0]']          \n",
      "                                                                                                  \n",
      " post_embedding (Embedding)  (None, 1, 32)                192064    ['post_input[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_20 (Flatten)        (None, 32)                   0         ['user_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_21 (Flatten)        (None, 32)                   0         ['post_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 64)                   0         ['flatten_20[0][0]',          \n",
      " )                                                                   'flatten_21[0][0]']          \n",
      "                                                                                                  \n",
      " layer1 (Dense)              (None, 32)                   2080      ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " layer2 (Dense)              (None, 16)                   528       ['layer1[0][0]']              \n",
      "                                                                                                  \n",
      " layer3 (Dense)              (None, 8)                    136       ['layer2[0][0]']              \n",
      "                                                                                                  \n",
      " prediction (Dense)          (None, 1)                    9         ['layer3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 210881 (823.75 KB)\n",
      "Trainable params: 210881 (823.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers = [64, 32, 16, 8]\n",
    "reg_layers = [0.01, 0.01, 0.01, 0.01]\n",
    "\n",
    "MLP_model = build_mlp_model(users_max_id, posts_max_id, layers, reg_layers)\n",
    "MLP_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7850c",
   "metadata": {},
   "source": [
    "## 5.2. Training the MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa2de712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "668/668 [==============================] - 4s 4ms/step - loss: 1.3463 - mean_squared_error: 1.0056 - compute_rmse: 0.8783 - val_loss: 0.5968 - val_mean_squared_error: 0.4876 - val_compute_rmse: 0.6951\n",
      "Epoch 2/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5725 - mean_squared_error: 0.4959 - compute_rmse: 0.7012 - val_loss: 0.5406 - val_mean_squared_error: 0.4851 - val_compute_rmse: 0.6930\n",
      "Epoch 3/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5406 - mean_squared_error: 0.4961 - compute_rmse: 0.7013 - val_loss: 0.5220 - val_mean_squared_error: 0.4854 - val_compute_rmse: 0.6930\n",
      "Epoch 4/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5274 - mean_squared_error: 0.4965 - compute_rmse: 0.7019 - val_loss: 0.5169 - val_mean_squared_error: 0.4910 - val_compute_rmse: 0.6980\n",
      "Epoch 5/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5199 - mean_squared_error: 0.4965 - compute_rmse: 0.7017 - val_loss: 0.5062 - val_mean_squared_error: 0.4852 - val_compute_rmse: 0.6930\n",
      "Epoch 6/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5153 - mean_squared_error: 0.4966 - compute_rmse: 0.7014 - val_loss: 0.5020 - val_mean_squared_error: 0.4852 - val_compute_rmse: 0.6933\n",
      "Epoch 7/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5114 - mean_squared_error: 0.4961 - compute_rmse: 0.7010 - val_loss: 0.4991 - val_mean_squared_error: 0.4851 - val_compute_rmse: 0.6931\n",
      "Epoch 8/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5089 - mean_squared_error: 0.4961 - compute_rmse: 0.7014 - val_loss: 0.4998 - val_mean_squared_error: 0.4884 - val_compute_rmse: 0.6960\n",
      "Epoch 9/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5072 - mean_squared_error: 0.4965 - compute_rmse: 0.7017 - val_loss: 0.4952 - val_mean_squared_error: 0.4854 - val_compute_rmse: 0.6934\n",
      "Epoch 10/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5054 - mean_squared_error: 0.4963 - compute_rmse: 0.7016 - val_loss: 0.4935 - val_mean_squared_error: 0.4852 - val_compute_rmse: 0.6932\n",
      "Epoch 11/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5045 - mean_squared_error: 0.4968 - compute_rmse: 0.7016 - val_loss: 0.4945 - val_mean_squared_error: 0.4875 - val_compute_rmse: 0.6953\n",
      "Epoch 12/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5032 - mean_squared_error: 0.4965 - compute_rmse: 0.7018 - val_loss: 0.4920 - val_mean_squared_error: 0.4859 - val_compute_rmse: 0.6939\n",
      "Epoch 13/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5021 - mean_squared_error: 0.4964 - compute_rmse: 0.7015 - val_loss: 0.4915 - val_mean_squared_error: 0.4860 - val_compute_rmse: 0.6933\n",
      "Epoch 14/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5012 - mean_squared_error: 0.4962 - compute_rmse: 0.7013 - val_loss: 0.4913 - val_mean_squared_error: 0.4868 - val_compute_rmse: 0.6947\n",
      "Epoch 15/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5007 - mean_squared_error: 0.4964 - compute_rmse: 0.7018 - val_loss: 0.4897 - val_mean_squared_error: 0.4858 - val_compute_rmse: 0.6938\n",
      "Epoch 15: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "validation_split = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(MLP_model, 'adam', batch_size, num_epochs, validation_split, \n",
    "                      input_data=[df_train.user_id.values, df_train.post_id.values],\n",
    "                      target_data=df_train.score.values,\n",
    "                        output_model_name='best_mlp_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e513e2fc",
   "metadata": {},
   "source": [
    "## 5.3. Loading the Trained MLP Model and Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "966447b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 1s 1ms/step\n",
      "The out-of-sample RMSE of rating predictions is 0.7027\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained MLP model with the best weights\n",
    "mlp_model = build_mlp_model(users_max_id, posts_max_id, layers, reg_layers)\n",
    "mlp_model = load_model_weights(mlp_model, os.path.join(output_path, 'best_mlp_model.hdf5'))\n",
    "\n",
    "# Generate predictions using the test data\n",
    "predicted_scores = mlp_model.predict([df_test.user_id.values, df_test.post_id.values])\n",
    "\n",
    "# Calculate the RMSE for the predictions\n",
    "rmse_error = calculate_rmse(df_test.score.values, predicted_scores)\n",
    "\n",
    "# Print the RMSE result\n",
    "print('The out-of-sample RMSE of rating predictions is', round(rmse_error, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb02f0e",
   "metadata": {},
   "source": [
    "# 6. Training and Testing the Neural Matrix Factorization Model\n",
    "## 6.1. Defining the NeuMF Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42b87a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neumf_model(num_users, num_posts, MF_dim, MF_reg, MLP_layers, MLP_regs):\n",
    "    # Ensure the number of layers matches the number of regularization parameters\n",
    "    assert len(MLP_layers) == len(MLP_regs)\n",
    "    num_MLP_layer = len(MLP_layers) # Number of layers in the MLP\n",
    "\n",
    "    # Define input layers for user and post IDs\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    post_input = Input(shape=(1,), dtype='int32', name='post_input')\n",
    "\n",
    "    # Embedding layers for MF\n",
    "    mf_user_embedding = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=MF_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mf_user_embedding',\n",
    "        embeddings_regularizer=l2(MF_reg[0]),\n",
    "        input_length=1)\n",
    "    mf_post_embedding = Embedding(\n",
    "        input_dim=num_posts + 1,\n",
    "        output_dim=MF_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mf_post_embedding',\n",
    "        embeddings_regularizer=l2(MF_reg[1]),\n",
    "        input_length=1)\n",
    "    \n",
    "    # Embedding layers for MLP\n",
    "    mlp_user_embedding = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=MLP_layers[0] // 2,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mlp_user_embedding',\n",
    "        embeddings_regularizer=l2(MLP_regs[0]),\n",
    "        input_length=1)\n",
    "    mlp_post_embedding = Embedding(\n",
    "        input_dim=num_posts + 1,\n",
    "        output_dim=MLP_layers[0] // 2,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mlp_post_embedding',\n",
    "        embeddings_regularizer=l2(MLP_regs[0]),\n",
    "        input_length=1) \n",
    "    \n",
    "    # Flatten the embeddings to prepare for concatenation\n",
    "    mf_user_latent = Flatten()(mf_user_embedding(user_input))\n",
    "    mf_post_latent = Flatten()(mf_post_embedding(post_input))\n",
    "    mf_vector = Multiply()([mf_user_latent, mf_post_latent])\n",
    "\n",
    "    # Flatten the embeddings to prepare for concatenation\n",
    "    mlp_user_latent = Flatten()(mlp_user_embedding(user_input))\n",
    "    mlp_post_latent = Flatten()(mlp_post_embedding(post_input))\n",
    "    mlp_vector = Concatenate(axis=-1)([mlp_user_latent, mlp_post_latent])\n",
    "    \n",
    "    # Concatenate the two latent vectors\n",
    "    predict_vector = Concatenate(axis=-1)([mf_vector, mlp_vector])\n",
    "    \n",
    "    # Add fully connected (dense) layers\n",
    "    for idx in range(1, num_MLP_layer):\n",
    "        layer = Dense(\n",
    "            units=MLP_layers[idx],\n",
    "            activation='relu',\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            kernel_regularizer=l2(MLP_regs[idx]),\n",
    "            name = 'layer%d' %idx)\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "    \n",
    "\n",
    "    # Concatenate the two latent vectors\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(predict_vector)\n",
    "    \n",
    "    # Create the model with user and post inputs and prediction as the output\n",
    "    model = Model([user_input, post_input], prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f97ea9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " post_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " mf_user_embedding (Embeddi  (None, 1, 8)                 4016      ['user_input[0][0]']          \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " mf_post_embedding (Embeddi  (None, 1, 8)                 48016     ['post_input[0][0]']          \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " mlp_user_embedding (Embedd  (None, 1, 32)                16064     ['user_input[0][0]']          \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " mlp_post_embedding (Embedd  (None, 1, 32)                192064    ['post_input[0][0]']          \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " flatten_24 (Flatten)        (None, 8)                    0         ['mf_user_embedding[0][0]']   \n",
      "                                                                                                  \n",
      " flatten_25 (Flatten)        (None, 8)                    0         ['mf_post_embedding[0][0]']   \n",
      "                                                                                                  \n",
      " flatten_26 (Flatten)        (None, 32)                   0         ['mlp_user_embedding[0][0]']  \n",
      "                                                                                                  \n",
      " flatten_27 (Flatten)        (None, 32)                   0         ['mlp_post_embedding[0][0]']  \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)       (None, 8)                    0         ['flatten_24[0][0]',          \n",
      "                                                                     'flatten_25[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate  (None, 64)                   0         ['flatten_26[0][0]',          \n",
      " )                                                                   'flatten_27[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate  (None, 72)                   0         ['multiply_6[0][0]',          \n",
      " )                                                                   'concatenate_8[0][0]']       \n",
      "                                                                                                  \n",
      " prediction (Dense)          (None, 1)                    73        ['concatenate_9[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 260233 (1016.54 KB)\n",
      "Trainable params: 260233 (1016.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MF_dim = 8\n",
    "MF_reg = (0.01, 0.01)\n",
    "MLP_layers = [64, 32, 16, 8]\n",
    "MLP_regs = [0.01, 0.01, 0.01, 0.01]\n",
    "\n",
    "NeuMF_model = build_neumf_model(\n",
    "    num_users=users_max_id,\n",
    "    num_posts=posts_max_id,\n",
    "    MF_dim=MF_dim,\n",
    "    MF_reg=MF_reg,\n",
    "    MLP_layers=MLP_layers,\n",
    "    MLP_regs=MLP_regs\n",
    ")\n",
    "NeuMF_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6b9c3",
   "metadata": {},
   "source": [
    "## 6.2. Training the NeuMF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb17b720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "668/668 [==============================] - 4s 4ms/step - loss: 3.0550 - mean_squared_error: 2.2874 - compute_rmse: 1.3865 - val_loss: 1.4988 - val_mean_squared_error: 0.7016 - val_compute_rmse: 0.8361\n",
      "Epoch 2/100\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 1.2522 - mean_squared_error: 0.6372 - compute_rmse: 0.7966 - val_loss: 1.0811 - val_mean_squared_error: 0.6031 - val_compute_rmse: 0.7748\n",
      "Epoch 3/100\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.9785 - mean_squared_error: 0.5849 - compute_rmse: 0.7627 - val_loss: 0.8945 - val_mean_squared_error: 0.5720 - val_compute_rmse: 0.7542\n",
      "Epoch 4/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.8345 - mean_squared_error: 0.5643 - compute_rmse: 0.7492 - val_loss: 0.7812 - val_mean_squared_error: 0.5532 - val_compute_rmse: 0.7412\n",
      "Epoch 5/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.7458 - mean_squared_error: 0.5542 - compute_rmse: 0.7420 - val_loss: 0.7085 - val_mean_squared_error: 0.5457 - val_compute_rmse: 0.7360\n",
      "Epoch 6/100\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.6840 - mean_squared_error: 0.5479 - compute_rmse: 0.7376 - val_loss: 0.6559 - val_mean_squared_error: 0.5412 - val_compute_rmse: 0.7328\n",
      "Epoch 7/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.6410 - mean_squared_error: 0.5439 - compute_rmse: 0.7349 - val_loss: 0.6243 - val_mean_squared_error: 0.5431 - val_compute_rmse: 0.7341\n",
      "Epoch 8/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.6089 - mean_squared_error: 0.5405 - compute_rmse: 0.7324 - val_loss: 0.5900 - val_mean_squared_error: 0.5349 - val_compute_rmse: 0.7287\n",
      "Epoch 9/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5843 - mean_squared_error: 0.5367 - compute_rmse: 0.7298 - val_loss: 0.5660 - val_mean_squared_error: 0.5267 - val_compute_rmse: 0.7223\n",
      "Epoch 10/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5638 - mean_squared_error: 0.5314 - compute_rmse: 0.7261 - val_loss: 0.5454 - val_mean_squared_error: 0.5196 - val_compute_rmse: 0.7175\n",
      "Epoch 11/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5453 - mean_squared_error: 0.5228 - compute_rmse: 0.7203 - val_loss: 0.5346 - val_mean_squared_error: 0.5158 - val_compute_rmse: 0.7153\n",
      "Epoch 12/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5328 - mean_squared_error: 0.5162 - compute_rmse: 0.7154 - val_loss: 0.5113 - val_mean_squared_error: 0.4982 - val_compute_rmse: 0.7027\n",
      "Epoch 13/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5203 - mean_squared_error: 0.5078 - compute_rmse: 0.7098 - val_loss: 0.5087 - val_mean_squared_error: 0.4977 - val_compute_rmse: 0.7023\n",
      "Epoch 14/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5115 - mean_squared_error: 0.5016 - compute_rmse: 0.7049 - val_loss: 0.5004 - val_mean_squared_error: 0.4919 - val_compute_rmse: 0.6981\n",
      "Epoch 15/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5056 - mean_squared_error: 0.4971 - compute_rmse: 0.7018 - val_loss: 0.4948 - val_mean_squared_error: 0.4880 - val_compute_rmse: 0.6954\n",
      "Epoch 16/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5021 - mean_squared_error: 0.4954 - compute_rmse: 0.7005 - val_loss: 0.4920 - val_mean_squared_error: 0.4865 - val_compute_rmse: 0.6942\n",
      "Epoch 17/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5009 - mean_squared_error: 0.4948 - compute_rmse: 0.7007 - val_loss: 0.4922 - val_mean_squared_error: 0.4860 - val_compute_rmse: 0.6938\n",
      "Epoch 18/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5012 - mean_squared_error: 0.4950 - compute_rmse: 0.7006 - val_loss: 0.4914 - val_mean_squared_error: 0.4859 - val_compute_rmse: 0.6938\n",
      "Epoch 19/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5010 - mean_squared_error: 0.4949 - compute_rmse: 0.7009 - val_loss: 0.4929 - val_mean_squared_error: 0.4855 - val_compute_rmse: 0.6934\n",
      "Epoch 20/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5045 - mean_squared_error: 0.4950 - compute_rmse: 0.6999 - val_loss: 0.4922 - val_mean_squared_error: 0.4855 - val_compute_rmse: 0.6935\n",
      "Epoch 21/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5016 - mean_squared_error: 0.4951 - compute_rmse: 0.7002 - val_loss: 0.4922 - val_mean_squared_error: 0.4857 - val_compute_rmse: 0.6936\n",
      "Epoch 22/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5020 - mean_squared_error: 0.4950 - compute_rmse: 0.7005 - val_loss: 0.4906 - val_mean_squared_error: 0.4854 - val_compute_rmse: 0.6935\n",
      "Epoch 23/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5000 - mean_squared_error: 0.4950 - compute_rmse: 0.7004 - val_loss: 0.4904 - val_mean_squared_error: 0.4853 - val_compute_rmse: 0.6932\n",
      "Epoch 24/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5004 - mean_squared_error: 0.4950 - compute_rmse: 0.7008 - val_loss: 0.4900 - val_mean_squared_error: 0.4858 - val_compute_rmse: 0.6937\n",
      "Epoch 25/100\n",
      "668/668 [==============================] - 2s 4ms/step - loss: 0.5004 - mean_squared_error: 0.4948 - compute_rmse: 0.7007 - val_loss: 0.4917 - val_mean_squared_error: 0.4854 - val_compute_rmse: 0.6933\n",
      "Epoch 26/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5007 - mean_squared_error: 0.4950 - compute_rmse: 0.7004 - val_loss: 0.4898 - val_mean_squared_error: 0.4856 - val_compute_rmse: 0.6935\n",
      "Epoch 27/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.5001 - mean_squared_error: 0.4949 - compute_rmse: 0.7001 - val_loss: 0.4896 - val_mean_squared_error: 0.4855 - val_compute_rmse: 0.6935\n",
      "Epoch 28/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.4990 - mean_squared_error: 0.4950 - compute_rmse: 0.7002 - val_loss: 0.4891 - val_mean_squared_error: 0.4858 - val_compute_rmse: 0.6937\n",
      "Epoch 29/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.4982 - mean_squared_error: 0.4950 - compute_rmse: 0.7007 - val_loss: 0.4879 - val_mean_squared_error: 0.4854 - val_compute_rmse: 0.6933\n",
      "Epoch 30/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.4982 - mean_squared_error: 0.4949 - compute_rmse: 0.7008 - val_loss: 0.4897 - val_mean_squared_error: 0.4857 - val_compute_rmse: 0.6936\n",
      "Epoch 31/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.4993 - mean_squared_error: 0.4948 - compute_rmse: 0.7006 - val_loss: 0.4897 - val_mean_squared_error: 0.4856 - val_compute_rmse: 0.6935\n",
      "Epoch 32/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.4996 - mean_squared_error: 0.4948 - compute_rmse: 0.7004 - val_loss: 0.4891 - val_mean_squared_error: 0.4854 - val_compute_rmse: 0.6934\n",
      "Epoch 33/100\n",
      "668/668 [==============================] - 2s 3ms/step - loss: 0.4986 - mean_squared_error: 0.4947 - compute_rmse: 0.7005 - val_loss: 0.4903 - val_mean_squared_error: 0.4855 - val_compute_rmse: 0.6935\n",
      "Epoch 33: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "validation_split = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(NeuMF_model, 'adam', batch_size, num_epochs, validation_split, \n",
    "                        input_data=[df_train.user_id.values, df_train.post_id.values],\n",
    "                        target_data=df_train.score.values,\n",
    "                        output_model_name='best_neumf_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d61830c",
   "metadata": {},
   "source": [
    "## 6.3. Loading the Trained NeuMF Model and Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "946c5dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 1s 1ms/step\n",
      "The out-of-sample RMSE of rating predictions is 0.7025\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained NeuMF model with the best weights\n",
    "neumf_model = build_neumf_model(\n",
    "    num_users=users_max_id,\n",
    "    num_posts=posts_max_id,\n",
    "    MF_dim=MF_dim,\n",
    "    MF_reg=MF_reg,\n",
    "    MLP_layers=MLP_layers,\n",
    "    MLP_regs=MLP_regs\n",
    ")\n",
    "neumf_model = load_model_weights(neumf_model, os.path.join(output_path, 'best_neumf_model.hdf5'))\n",
    "\n",
    "# Generate predictions using the test data\n",
    "predicted_scores = neumf_model.predict([df_test.user_id.values, df_test.post_id.values])\n",
    "\n",
    "# Calculate the RMSE for the predictions\n",
    "rmse_error = calculate_rmse(df_test.score.values, predicted_scores)\n",
    "\n",
    "# Print the RMSE result\n",
    "print('The out-of-sample RMSE of rating predictions is', round(rmse_error, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
