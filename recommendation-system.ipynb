{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ee1b2104-56a7-4b64-aa99-8327f5c73d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Multiply, Concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# from tensorflow.keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Set the output path for saving the model\n",
    "os.environ['CURRENT_PATH'] = os.getcwd()\n",
    "output_path = os.path.join(os.environ['CURRENT_PATH'], 'output')\n",
    "\n",
    "# visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the datasets\n",
    "posts_df = pd.read_csv('datasets/post_data.csv')\n",
    "views_df = pd.read_csv('datasets/view_data.csv')\n",
    "users_df = pd.read_csv('datasets/user_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470643a",
   "metadata": {},
   "source": [
    "# 2. DATA PRE-PROCESSING\n",
    "## 2.1. Generating Score Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a7ab3f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5eece14ffc13ae660900008b</td>\n",
       "      <td>136781766</td>\n",
       "      <td>01/01/2019 01:30 PM</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5eece14efc13ae660900003c</td>\n",
       "      <td>43094523</td>\n",
       "      <td>01/01/2019 01:33 PM</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5eece14efc13ae6609000025</td>\n",
       "      <td>42428071</td>\n",
       "      <td>01/01/2019 01:43 PM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5eece14ffc13ae66090001d4</td>\n",
       "      <td>76472880</td>\n",
       "      <td>01/01/2019 01:54 PM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5eece14ffc13ae66090000ac</td>\n",
       "      <td>202721843</td>\n",
       "      <td>01/01/2019 02:00 PM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user_id    post_id           time_stamp  score\n",
       "0  5eece14ffc13ae660900008b  136781766  01/01/2019 01:30 PM      2\n",
       "1  5eece14efc13ae660900003c   43094523  01/01/2019 01:33 PM      2\n",
       "2  5eece14efc13ae6609000025   42428071  01/01/2019 01:43 PM      3\n",
       "3  5eece14ffc13ae66090001d4   76472880  01/01/2019 01:54 PM      1\n",
       "4  5eece14ffc13ae66090000ac  202721843  01/01/2019 02:00 PM      3"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views_df_with_scores = pd.DataFrame(views_df)\n",
    "\n",
    "# Generate random probabilities for 1, 2, and 3\n",
    "probs = np.random.dirichlet(np.ones(3))\n",
    "\n",
    "# Assign probabilities for the scores\n",
    "scores = np.random.choice(\n",
    "    [1, 2, 3],\n",
    "    size=len(views_df),\n",
    "    p=probs\n",
    ")\n",
    "\n",
    "# Add the score column to the dataframe\n",
    "views_df_with_scores['score'] = scores\n",
    "\n",
    "views_df_with_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb194f",
   "metadata": {},
   "source": [
    "## 2.2. Data Cleaning and Transformation for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3baa7612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>813</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>202</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>195</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>469</td>\n",
       "      <td>418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173</td>\n",
       "      <td>1217</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  post_id  score\n",
       "0      140      813      2\n",
       "1       61      202      2\n",
       "2       38      195      3\n",
       "3      469      418      1\n",
       "4      173     1217      3"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the columns that are not needed and remove the rows with missing title values\n",
    "cleaned_data = views_df_with_scores.drop(['time_stamp'], axis=1)\n",
    "\n",
    "# Drop the duplicates\n",
    "cleaned_data = cleaned_data.drop_duplicates()\n",
    "\n",
    "# Map user_id and post_id to numeric indices\n",
    "cleaned_data[\"user_id\"] = cleaned_data[\"user_id\"].astype(\"category\").cat.codes + 1\n",
    "cleaned_data[\"post_id\"] = cleaned_data[\"post_id\"].astype(\"category\").cat.codes + 1\n",
    "\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "75aaeb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 501 unique users and 6001 unique posts in this data set\n"
     ]
    }
   ],
   "source": [
    "unique_users_num = len(cleaned_data.user_id.unique())\n",
    "unique_posts_num = len(cleaned_data.post_id.unique())\n",
    "\n",
    "print('There are {} unique users and {} unique posts in this data set'.format(unique_users_num, unique_posts_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7c7cde41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 501 distinct users, and the max of user_id is also 501\n",
      "There are 6001 distinct posts, and the max of post_id is also 6001\n"
     ]
    }
   ],
   "source": [
    "users_max_id = cleaned_data.user_id.max()\n",
    "posts_max_id = cleaned_data.post_id.max()\n",
    "\n",
    "print('There are {} distinct users, and the max of user_id is also {}'.format(unique_users_num, users_max_id))\n",
    "print('There are {} distinct posts, and the max of post_id is also {}'.format(unique_posts_num, posts_max_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81826817",
   "metadata": {},
   "source": [
    "## 2.3. Splitting Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fc0ede24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data set:\n",
      "(57076, 3)\n",
      "shape of test data set:\n",
      "(14270, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(cleaned_data, test_size=0.2, shuffle=True, random_state=99)\n",
    "print('shape of training data set:')\n",
    "print(df_train.shape)\n",
    "print('shape of test data set:')\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5852b0df",
   "metadata": {},
   "source": [
    "# 3. Model Training, Evaluation, and Weights Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3dfa6e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model training function\n",
    "def train_model(model, optimizer, batch_size, num_epochs, validation_split, input_data, target_data, output_model_name):\n",
    "    # Define a custom metric for Root Mean Squared Error (RMSE)\n",
    "    def compute_rmse(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "\n",
    "    # Compile the model with the specified optimizer and loss function\n",
    "    model.compile(\n",
    "        optimizer=optimizer.lower(),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error', compute_rmse]\n",
    "    )\n",
    "\n",
    "    # Define callbacks for early stopping and model checkpointing\n",
    "    early_stopping = EarlyStopping(monitor='val_compute_rmse', patience=10, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        filepath=os.path.join(output_path, output_model_name),\n",
    "        monitor='val_compute_rmse',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True\n",
    "    )\n",
    "\n",
    "    # Train the model and return the history\n",
    "    history = model.fit(\n",
    "        x=input_data,\n",
    "        y=target_data,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "# Define the model's weights loading function\n",
    "def load_model_weights(model, weights_file_path):\n",
    "    model.load_weights(weights_file_path)\n",
    "    return model\n",
    "\n",
    "# Define the model evaluation function\n",
    "calculate_rmse = lambda true_values, predicted_values: np.sqrt(\n",
    "    np.mean(np.square(np.squeeze(predicted_values) - np.squeeze(true_values)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0921c8ce",
   "metadata": {},
   "source": [
    "# 4. Training and Testing the Generalized Matrix Factorization Model\n",
    "## 4.1. Defining the GMF Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "12007f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gmf_model(num_users, num_posts, latent_dim, user_reg, post_reg):\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    post_input = Input(shape=(1,), dtype='int32', name='post_input')\n",
    "\n",
    "    # Embedding layers\n",
    "    user_embedding = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=latent_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='user_embedding',\n",
    "        embeddings_regularizer=l2(user_reg),\n",
    "        input_length=1\n",
    "    )\n",
    "    post_embedding = Embedding(\n",
    "        input_dim=num_posts + 1,\n",
    "        output_dim=latent_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='post_embedding',\n",
    "        embeddings_regularizer=l2(post_reg),\n",
    "        input_length=1\n",
    "    )\n",
    "\n",
    "    # Flatten embedding vectors\n",
    "    user_latent = Flatten()(user_embedding(user_input))\n",
    "    post_latent = Flatten()(post_embedding(post_input))\n",
    "\n",
    "    # Combine user and post embeddings\n",
    "    interaction_vector = Multiply()([user_latent, post_latent])\n",
    "\n",
    "    # Output layer\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(interaction_vector)\n",
    "\n",
    "    # Create and return the model\n",
    "    model = Model([user_input, post_input], prediction)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e0dc2278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_49\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " post_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)  (None, 1, 10)                5020      ['user_input[0][0]']          \n",
      "                                                                                                  \n",
      " post_embedding (Embedding)  (None, 1, 10)                60020     ['post_input[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_138 (Flatten)       (None, 10)                   0         ['user_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_139 (Flatten)       (None, 10)                   0         ['post_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " multiply_35 (Multiply)      (None, 10)                   0         ['flatten_138[0][0]',         \n",
      "                                                                     'flatten_139[0][0]']         \n",
      "                                                                                                  \n",
      " prediction (Dense)          (None, 1)                    11        ['multiply_35[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 65051 (254.11 KB)\n",
      "Trainable params: 65051 (254.11 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 10\n",
    "user_reg = 0\n",
    "post_reg = 0\n",
    "\n",
    "GMF_model = build_gmf_model(users_max_id, posts_max_id, latent_dim, user_reg, post_reg)\n",
    "GMF_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1872b5",
   "metadata": {},
   "source": [
    "## 4.2. Training the GMF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5b1c0408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "669/669 [==============================] - 3s 3ms/step - loss: 4.1828 - mean_squared_error: 4.1828 - compute_rmse: 2.0367 - val_loss: 3.0643 - val_mean_squared_error: 3.0643 - val_compute_rmse: 1.7489\n",
      "Epoch 2/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 2.0300 - mean_squared_error: 2.0300 - compute_rmse: 1.4051 - val_loss: 1.0247 - val_mean_squared_error: 1.0247 - val_compute_rmse: 1.0103\n",
      "Epoch 3/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.6156 - mean_squared_error: 0.6156 - compute_rmse: 0.7805 - val_loss: 0.5812 - val_mean_squared_error: 0.5812 - val_compute_rmse: 0.7606\n",
      "Epoch 4/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4382 - mean_squared_error: 0.4382 - compute_rmse: 0.6603 - val_loss: 0.5794 - val_mean_squared_error: 0.5794 - val_compute_rmse: 0.7593\n",
      "Epoch 5/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.3693 - mean_squared_error: 0.3693 - compute_rmse: 0.6061 - val_loss: 0.6111 - val_mean_squared_error: 0.6111 - val_compute_rmse: 0.7797\n",
      "Epoch 6/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.3142 - mean_squared_error: 0.3142 - compute_rmse: 0.5587 - val_loss: 0.6547 - val_mean_squared_error: 0.6547 - val_compute_rmse: 0.8069\n",
      "Epoch 7/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.2725 - mean_squared_error: 0.2725 - compute_rmse: 0.5201 - val_loss: 0.6992 - val_mean_squared_error: 0.6992 - val_compute_rmse: 0.8338\n",
      "Epoch 8/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.2393 - mean_squared_error: 0.2393 - compute_rmse: 0.4870 - val_loss: 0.7409 - val_mean_squared_error: 0.7409 - val_compute_rmse: 0.8583\n",
      "Epoch 9/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.2121 - mean_squared_error: 0.2121 - compute_rmse: 0.4582 - val_loss: 0.7749 - val_mean_squared_error: 0.7749 - val_compute_rmse: 0.8779\n",
      "Epoch 10/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.1890 - mean_squared_error: 0.1890 - compute_rmse: 0.4324 - val_loss: 0.8133 - val_mean_squared_error: 0.8133 - val_compute_rmse: 0.8993\n",
      "Epoch 11/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.1694 - mean_squared_error: 0.1694 - compute_rmse: 0.4090 - val_loss: 0.8468 - val_mean_squared_error: 0.8468 - val_compute_rmse: 0.9176\n",
      "Epoch 12/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.1523 - mean_squared_error: 0.1523 - compute_rmse: 0.3879 - val_loss: 0.8760 - val_mean_squared_error: 0.8760 - val_compute_rmse: 0.9333\n",
      "Epoch 13/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.1377 - mean_squared_error: 0.1377 - compute_rmse: 0.3682 - val_loss: 0.9095 - val_mean_squared_error: 0.9095 - val_compute_rmse: 0.9510\n",
      "Epoch 14/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.1247 - mean_squared_error: 0.1247 - compute_rmse: 0.3503 - val_loss: 0.9388 - val_mean_squared_error: 0.9388 - val_compute_rmse: 0.9661\n",
      "Epoch 14: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "validation_split = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(GMF_model, 'adam', batch_size, num_epochs, validation_split, \n",
    "                      input_data=[df_train.user_id.values, df_train.post_id.values],\n",
    "                      target_data=df_train.score.values,\n",
    "                        output_model_name='best_gmf_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d5113",
   "metadata": {},
   "source": [
    "## 4.3. Loading the Trained GMF Model and Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f7c9db2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/446 [==============================] - 1s 1ms/step\n",
      "The out-of-sample RMSE of rating predictions is 0.7562\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained GMF model with the best weights\n",
    "gmf_model = build_gmf_model(users_max_id, posts_max_id, latent_dim, user_reg, post_reg)\n",
    "gmf_model = load_model_weights(gmf_model, os.path.join(output_path, 'best_gmf_model.hdf5'))\n",
    "\n",
    "# Generate predictions using the test data\n",
    "predicted_scores = gmf_model.predict([df_test.user_id.values, df_test.post_id.values])\n",
    "\n",
    "# Calculate the RMSE for the predictions\n",
    "rmse_error = calculate_rmse(df_test.score.values, predicted_scores)\n",
    "\n",
    "# Print the RMSE result\n",
    "print('The out-of-sample RMSE of rating predictions is', round(rmse_error, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b25dd",
   "metadata": {},
   "source": [
    "# 5. Training and Testing the Multi-Layer Perceptron Model\n",
    "## 5.1. Defining the MLP Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "72c50f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp_model(num_users, num_posts, layers, reg_layers):\n",
    "    # Ensure the number of layers matches the number of regularization parameters\n",
    "    assert len(layers) == len(reg_layers)\n",
    "    num_layer = len(layers)  # Number of layers in the MLP\n",
    "\n",
    "    # Define input layers for user and post IDs\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    post_input = Input(shape=(1,), dtype='int32', name='post_input')\n",
    "\n",
    "    # Define embedding layers for users and posts\n",
    "    user_embedding = Embedding(\n",
    "        input_dim=num_users + 1,           \n",
    "        output_dim=layers[0] // 2,        \n",
    "        embeddings_initializer='uniform', \n",
    "        name='user_embedding',           \n",
    "        embeddings_regularizer=l2(reg_layers[0]),  \n",
    "        input_length=1)                   \n",
    "    \n",
    "    post_embedding = Embedding(\n",
    "        input_dim=num_posts + 1,         \n",
    "        output_dim=layers[0] // 2,       \n",
    "        embeddings_initializer='uniform', \n",
    "        name='post_embedding',           \n",
    "        embeddings_regularizer=l2(reg_layers[0]), \n",
    "        input_length=1)                   \n",
    "\n",
    "    # Flatten the embeddings to prepare for concatenation\n",
    "    user_latent = Flatten()(user_embedding(user_input))  \n",
    "    item_latent = Flatten()(post_embedding(post_input))  \n",
    "\n",
    "    # Concatenate the user and item embedding vectors\n",
    "    vector = Concatenate(axis=-1)([user_latent, item_latent])\n",
    "\n",
    "    # Add fully connected (dense) layers\n",
    "    for idx in range(1, num_layer): \n",
    "        layer = Dense(\n",
    "            units=layers[idx],                   \n",
    "            activation='relu',                   \n",
    "            kernel_initializer='glorot_uniform',\n",
    "            kernel_regularizer=l2(reg_layers[idx]), \n",
    "            name=f'layer{idx}')                 \n",
    "        vector = layer(vector) \n",
    "    \n",
    "    # Add the final prediction layer with a single output\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(vector)\n",
    "\n",
    "    # Create the model with user and post inputs and prediction as the output\n",
    "    model = Model([user_input, post_input], prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "71e8f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_51\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " post_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)  (None, 1, 32)                16064     ['user_input[0][0]']          \n",
      "                                                                                                  \n",
      " post_embedding (Embedding)  (None, 1, 32)                192064    ['post_input[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_142 (Flatten)       (None, 32)                   0         ['user_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_143 (Flatten)       (None, 32)                   0         ['post_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_54 (Concatenat  (None, 64)                   0         ['flatten_142[0][0]',         \n",
      " e)                                                                  'flatten_143[0][0]']         \n",
      "                                                                                                  \n",
      " layer1 (Dense)              (None, 32)                   2080      ['concatenate_54[0][0]']      \n",
      "                                                                                                  \n",
      " layer2 (Dense)              (None, 16)                   528       ['layer1[0][0]']              \n",
      "                                                                                                  \n",
      " layer3 (Dense)              (None, 8)                    136       ['layer2[0][0]']              \n",
      "                                                                                                  \n",
      " prediction (Dense)          (None, 1)                    9         ['layer3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 210881 (823.75 KB)\n",
      "Trainable params: 210881 (823.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers = [64, 32, 16, 8]\n",
    "reg_layers = [0, 0, 0, 0]\n",
    "\n",
    "MLP_model = build_mlp_model(users_max_id, posts_max_id, layers, reg_layers)\n",
    "MLP_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7850c",
   "metadata": {},
   "source": [
    "## 5.2. Training the MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "aa2de712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "669/669 [==============================] - 4s 4ms/step - loss: 1.0263 - mean_squared_error: 1.0263 - compute_rmse: 0.8984 - val_loss: 0.4885 - val_mean_squared_error: 0.4885 - val_compute_rmse: 0.6973\n",
      "Epoch 2/100\n",
      "669/669 [==============================] - 3s 4ms/step - loss: 0.4777 - mean_squared_error: 0.4777 - compute_rmse: 0.6896 - val_loss: 0.4906 - val_mean_squared_error: 0.4906 - val_compute_rmse: 0.6990\n",
      "Epoch 3/100\n",
      "669/669 [==============================] - 2s 4ms/step - loss: 0.4494 - mean_squared_error: 0.4494 - compute_rmse: 0.6687 - val_loss: 0.5101 - val_mean_squared_error: 0.5101 - val_compute_rmse: 0.7125\n",
      "Epoch 4/100\n",
      "669/669 [==============================] - 3s 4ms/step - loss: 0.4073 - mean_squared_error: 0.4073 - compute_rmse: 0.6364 - val_loss: 0.5351 - val_mean_squared_error: 0.5351 - val_compute_rmse: 0.7298\n",
      "Epoch 5/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.3441 - mean_squared_error: 0.3441 - compute_rmse: 0.5845 - val_loss: 0.5869 - val_mean_squared_error: 0.5869 - val_compute_rmse: 0.7642\n",
      "Epoch 6/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.2733 - mean_squared_error: 0.2733 - compute_rmse: 0.5202 - val_loss: 0.6369 - val_mean_squared_error: 0.6369 - val_compute_rmse: 0.7959\n",
      "Epoch 7/100\n",
      "669/669 [==============================] - 3s 4ms/step - loss: 0.2128 - mean_squared_error: 0.2128 - compute_rmse: 0.4587 - val_loss: 0.7013 - val_mean_squared_error: 0.7013 - val_compute_rmse: 0.8351\n",
      "Epoch 8/100\n",
      "669/669 [==============================] - 2s 4ms/step - loss: 0.1664 - mean_squared_error: 0.1664 - compute_rmse: 0.4051 - val_loss: 0.7407 - val_mean_squared_error: 0.7407 - val_compute_rmse: 0.8581\n",
      "Epoch 9/100\n",
      "669/669 [==============================] - 3s 4ms/step - loss: 0.1324 - mean_squared_error: 0.1324 - compute_rmse: 0.3611 - val_loss: 0.7610 - val_mean_squared_error: 0.7610 - val_compute_rmse: 0.8696\n",
      "Epoch 10/100\n",
      "669/669 [==============================] - 3s 4ms/step - loss: 0.1070 - mean_squared_error: 0.1070 - compute_rmse: 0.3242 - val_loss: 0.7867 - val_mean_squared_error: 0.7867 - val_compute_rmse: 0.8844\n",
      "Epoch 11/100\n",
      "669/669 [==============================] - 3s 4ms/step - loss: 0.0883 - mean_squared_error: 0.0883 - compute_rmse: 0.2942 - val_loss: 0.8130 - val_mean_squared_error: 0.8130 - val_compute_rmse: 0.8989\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "validation_split = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(MLP_model, 'adam', batch_size, num_epochs, validation_split, \n",
    "                      input_data=[df_train.user_id.values, df_train.post_id.values],\n",
    "                      target_data=df_train.score.values,\n",
    "                        output_model_name='best_mlp_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e513e2fc",
   "metadata": {},
   "source": [
    "## 5.3. Loading the Trained MLP Model and Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "966447b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/446 [==============================] - 1s 1ms/step\n",
      "The out-of-sample RMSE of rating predictions is 0.6982\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained MLP model with the best weights\n",
    "mlp_model = build_mlp_model(users_max_id, posts_max_id, layers, reg_layers)\n",
    "mlp_model = load_model_weights(mlp_model, os.path.join(output_path, 'best_mlp_model.hdf5'))\n",
    "\n",
    "# Generate predictions using the test data\n",
    "predicted_scores = mlp_model.predict([df_test.user_id.values, df_test.post_id.values])\n",
    "\n",
    "# Calculate the RMSE for the predictions\n",
    "rmse_error = calculate_rmse(df_test.score.values, predicted_scores)\n",
    "\n",
    "# Print the RMSE result\n",
    "print('The out-of-sample RMSE of rating predictions is', round(rmse_error, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb02f0e",
   "metadata": {},
   "source": [
    "# 6. Training and Testing the Neural Matrix Factorization Model\n",
    "## 6.1. Defining the NeuMF Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "42b87a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neumf_model(num_users, num_posts, MF_dim, MF_reg, MLP_layers, MLP_regs):\n",
    "    # Ensure the number of layers matches the number of regularization parameters\n",
    "    assert len(MLP_layers) == len(MLP_regs)\n",
    "    num_MLP_layer = len(MLP_layers) # Number of layers in the MLP\n",
    "\n",
    "    # Define input layers for user and post IDs\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    post_input = Input(shape=(1,), dtype='int32', name='post_input')\n",
    "\n",
    "    # Embedding layers for MF\n",
    "    mf_user_embedding = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=MF_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mf_user_embedding',\n",
    "        embeddings_regularizer=l2(MF_reg[0]),\n",
    "        input_length=1)\n",
    "    mf_post_embedding = Embedding(\n",
    "        input_dim=num_posts + 1,\n",
    "        output_dim=MF_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mf_post_embedding',\n",
    "        embeddings_regularizer=l2(MF_reg[1]),\n",
    "        input_length=1)\n",
    "    \n",
    "    # Embedding layers for MLP\n",
    "    mlp_user_embedding = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=MLP_layers[0] // 2,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mlp_user_embedding',\n",
    "        embeddings_regularizer=l2(MLP_regs[0]),\n",
    "        input_length=1)\n",
    "    mlp_post_embedding = Embedding(\n",
    "        input_dim=num_posts + 1,\n",
    "        output_dim=MLP_layers[0] // 2,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mlp_post_embedding',\n",
    "        embeddings_regularizer=l2(MLP_regs[0]),\n",
    "        input_length=1) \n",
    "    \n",
    "    # Flatten the embeddings to prepare for concatenation\n",
    "    mf_user_latent = Flatten()(mf_user_embedding(user_input))\n",
    "    mf_post_latent = Flatten()(mf_post_embedding(post_input))\n",
    "    mf_vector = Multiply()([mf_user_latent, mf_post_latent])\n",
    "\n",
    "    # Flatten the embeddings to prepare for concatenation\n",
    "    mlp_user_latent = Flatten()(mlp_user_embedding(user_input))\n",
    "    mlp_post_latent = Flatten()(mlp_post_embedding(post_input))\n",
    "    mlp_vector = Concatenate(axis=-1)([mlp_user_latent, mlp_post_latent])\n",
    "    \n",
    "    # Concatenate the two latent vectors\n",
    "    predict_vector = Concatenate(axis=-1)([mf_vector, mlp_vector])\n",
    "    \n",
    "    # Add fully connected (dense) layers\n",
    "    for idx in range(1, num_MLP_layer):\n",
    "        layer = Dense(\n",
    "            units=MLP_layers[idx],\n",
    "            activation='relu',\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            kernel_regularizer=l2(MLP_regs[idx]),\n",
    "            name = 'layer%d' %idx)\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "    \n",
    "\n",
    "    # Concatenate the two latent vectors\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(predict_vector)\n",
    "    \n",
    "    # Create the model with user and post inputs and prediction as the output\n",
    "    model = Model([user_input, post_input], prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f97ea9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_53\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " post_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " mf_user_embedding (Embeddi  (None, 1, 8)                 4016      ['user_input[0][0]']          \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " mf_post_embedding (Embeddi  (None, 1, 8)                 48016     ['post_input[0][0]']          \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " mlp_user_embedding (Embedd  (None, 1, 32)                16064     ['user_input[0][0]']          \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " mlp_post_embedding (Embedd  (None, 1, 32)                192064    ['post_input[0][0]']          \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " flatten_146 (Flatten)       (None, 8)                    0         ['mf_user_embedding[0][0]']   \n",
      "                                                                                                  \n",
      " flatten_147 (Flatten)       (None, 8)                    0         ['mf_post_embedding[0][0]']   \n",
      "                                                                                                  \n",
      " flatten_148 (Flatten)       (None, 32)                   0         ['mlp_user_embedding[0][0]']  \n",
      "                                                                                                  \n",
      " flatten_149 (Flatten)       (None, 32)                   0         ['mlp_post_embedding[0][0]']  \n",
      "                                                                                                  \n",
      " multiply_37 (Multiply)      (None, 8)                    0         ['flatten_146[0][0]',         \n",
      "                                                                     'flatten_147[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_56 (Concatenat  (None, 64)                   0         ['flatten_148[0][0]',         \n",
      " e)                                                                  'flatten_149[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_57 (Concatenat  (None, 72)                   0         ['multiply_37[0][0]',         \n",
      " e)                                                                  'concatenate_56[0][0]']      \n",
      "                                                                                                  \n",
      " prediction (Dense)          (None, 1)                    73        ['concatenate_57[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 260233 (1016.54 KB)\n",
      "Trainable params: 260233 (1016.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MF_dim = 8\n",
    "MF_reg = (0.01, 0.01)\n",
    "MLP_layers = [64, 32, 16, 8]\n",
    "MLP_regs = [0.01, 0.01, 0.01, 0.01]\n",
    "\n",
    "NeuMF_model = build_neumf_model(\n",
    "    num_users=users_max_id,\n",
    "    num_posts=posts_max_id,\n",
    "    MF_dim=MF_dim,\n",
    "    MF_reg=MF_reg,\n",
    "    MLP_layers=MLP_layers,\n",
    "    MLP_regs=MLP_regs\n",
    ")\n",
    "NeuMF_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6b9c3",
   "metadata": {},
   "source": [
    "## 6.2. Training the NeuMF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bb17b720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "669/669 [==============================] - 3s 4ms/step - loss: 2.4198 - mean_squared_error: 1.8078 - compute_rmse: 1.2480 - val_loss: 1.2519 - val_mean_squared_error: 0.6412 - val_compute_rmse: 0.7990\n",
      "Epoch 2/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 1.0603 - mean_squared_error: 0.5983 - compute_rmse: 0.7718 - val_loss: 0.9251 - val_mean_squared_error: 0.5703 - val_compute_rmse: 0.7535\n",
      "Epoch 3/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.8477 - mean_squared_error: 0.5593 - compute_rmse: 0.7461 - val_loss: 0.7791 - val_mean_squared_error: 0.5491 - val_compute_rmse: 0.7394\n",
      "Epoch 4/100\n",
      "669/669 [==============================] - 3s 4ms/step - loss: 0.7377 - mean_squared_error: 0.5440 - compute_rmse: 0.7360 - val_loss: 0.6925 - val_mean_squared_error: 0.5358 - val_compute_rmse: 0.7305\n",
      "Epoch 5/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.6679 - mean_squared_error: 0.5355 - compute_rmse: 0.7302 - val_loss: 0.6349 - val_mean_squared_error: 0.5253 - val_compute_rmse: 0.7232\n",
      "Epoch 6/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.6224 - mean_squared_error: 0.5301 - compute_rmse: 0.7263 - val_loss: 0.5919 - val_mean_squared_error: 0.5176 - val_compute_rmse: 0.7182\n",
      "Epoch 7/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.5906 - mean_squared_error: 0.5275 - compute_rmse: 0.7247 - val_loss: 0.5709 - val_mean_squared_error: 0.5182 - val_compute_rmse: 0.7182\n",
      "Epoch 8/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.5640 - mean_squared_error: 0.5205 - compute_rmse: 0.7197 - val_loss: 0.5443 - val_mean_squared_error: 0.5074 - val_compute_rmse: 0.7106\n",
      "Epoch 9/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.5465 - mean_squared_error: 0.5158 - compute_rmse: 0.7167 - val_loss: 0.5292 - val_mean_squared_error: 0.5050 - val_compute_rmse: 0.7092\n",
      "Epoch 10/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.5297 - mean_squared_error: 0.5091 - compute_rmse: 0.7118 - val_loss: 0.5154 - val_mean_squared_error: 0.4996 - val_compute_rmse: 0.7053\n",
      "Epoch 11/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.5165 - mean_squared_error: 0.5021 - compute_rmse: 0.7069 - val_loss: 0.5063 - val_mean_squared_error: 0.4940 - val_compute_rmse: 0.7013\n",
      "Epoch 12/100\n",
      "669/669 [==============================] - 2s 4ms/step - loss: 0.5065 - mean_squared_error: 0.4949 - compute_rmse: 0.7020 - val_loss: 0.4968 - val_mean_squared_error: 0.4869 - val_compute_rmse: 0.6963\n",
      "Epoch 13/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.5006 - mean_squared_error: 0.4903 - compute_rmse: 0.6988 - val_loss: 0.4923 - val_mean_squared_error: 0.4833 - val_compute_rmse: 0.6937\n",
      "Epoch 14/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4955 - mean_squared_error: 0.4867 - compute_rmse: 0.6962 - val_loss: 0.4889 - val_mean_squared_error: 0.4812 - val_compute_rmse: 0.6923\n",
      "Epoch 15/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4936 - mean_squared_error: 0.4857 - compute_rmse: 0.6955 - val_loss: 0.4868 - val_mean_squared_error: 0.4807 - val_compute_rmse: 0.6919\n",
      "Epoch 16/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4920 - mean_squared_error: 0.4854 - compute_rmse: 0.6951 - val_loss: 0.4861 - val_mean_squared_error: 0.4801 - val_compute_rmse: 0.6915\n",
      "Epoch 17/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4914 - mean_squared_error: 0.4853 - compute_rmse: 0.6951 - val_loss: 0.4856 - val_mean_squared_error: 0.4799 - val_compute_rmse: 0.6913\n",
      "Epoch 18/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4918 - mean_squared_error: 0.4853 - compute_rmse: 0.6951 - val_loss: 0.4877 - val_mean_squared_error: 0.4801 - val_compute_rmse: 0.6915\n",
      "Epoch 19/100\n",
      "669/669 [==============================] - 2s 4ms/step - loss: 0.4913 - mean_squared_error: 0.4853 - compute_rmse: 0.6951 - val_loss: 0.4837 - val_mean_squared_error: 0.4798 - val_compute_rmse: 0.6913\n",
      "Epoch 20/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4909 - mean_squared_error: 0.4853 - compute_rmse: 0.6950 - val_loss: 0.4860 - val_mean_squared_error: 0.4800 - val_compute_rmse: 0.6914\n",
      "Epoch 21/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4909 - mean_squared_error: 0.4853 - compute_rmse: 0.6951 - val_loss: 0.4844 - val_mean_squared_error: 0.4799 - val_compute_rmse: 0.6914\n",
      "Epoch 22/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4891 - mean_squared_error: 0.4852 - compute_rmse: 0.6951 - val_loss: 0.4830 - val_mean_squared_error: 0.4800 - val_compute_rmse: 0.6914\n",
      "Epoch 23/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4887 - mean_squared_error: 0.4852 - compute_rmse: 0.6952 - val_loss: 0.4834 - val_mean_squared_error: 0.4800 - val_compute_rmse: 0.6914\n",
      "Epoch 24/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4893 - mean_squared_error: 0.4852 - compute_rmse: 0.6950 - val_loss: 0.4840 - val_mean_squared_error: 0.4801 - val_compute_rmse: 0.6915\n",
      "Epoch 25/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4899 - mean_squared_error: 0.4851 - compute_rmse: 0.6951 - val_loss: 0.4862 - val_mean_squared_error: 0.4801 - val_compute_rmse: 0.6914\n",
      "Epoch 26/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4911 - mean_squared_error: 0.4851 - compute_rmse: 0.6950 - val_loss: 0.4861 - val_mean_squared_error: 0.4800 - val_compute_rmse: 0.6914\n",
      "Epoch 27/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4914 - mean_squared_error: 0.4848 - compute_rmse: 0.6949 - val_loss: 0.4858 - val_mean_squared_error: 0.4801 - val_compute_rmse: 0.6915\n",
      "Epoch 28/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4907 - mean_squared_error: 0.4847 - compute_rmse: 0.6948 - val_loss: 0.4855 - val_mean_squared_error: 0.4802 - val_compute_rmse: 0.6916\n",
      "Epoch 29/100\n",
      "669/669 [==============================] - 2s 3ms/step - loss: 0.4910 - mean_squared_error: 0.4845 - compute_rmse: 0.6945 - val_loss: 0.4863 - val_mean_squared_error: 0.4804 - val_compute_rmse: 0.6917\n",
      "Epoch 29: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "validation_split = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(NeuMF_model, 'adam', batch_size, num_epochs, validation_split, \n",
    "                        input_data=[df_train.user_id.values, df_train.post_id.values],\n",
    "                        target_data=df_train.score.values,\n",
    "                        output_model_name='best_neumf_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d61830c",
   "metadata": {},
   "source": [
    "## 6.3. Loading the Trained NeuMF Model and Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "946c5dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/446 [==============================] - 1s 1ms/step\n",
      "The out-of-sample RMSE of rating predictions is 0.693\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained NeuMF model with the best weights\n",
    "neumf_model = build_neumf_model(\n",
    "    num_users=users_max_id,\n",
    "    num_posts=posts_max_id,\n",
    "    MF_dim=MF_dim,\n",
    "    MF_reg=MF_reg,\n",
    "    MLP_layers=MLP_layers,\n",
    "    MLP_regs=MLP_regs\n",
    ")\n",
    "neumf_model = load_model_weights(neumf_model, os.path.join(output_path, 'best_neumf_model.hdf5'))\n",
    "\n",
    "# Generate predictions using the test data\n",
    "predicted_scores = neumf_model.predict([df_test.user_id.values, df_test.post_id.values])\n",
    "\n",
    "# Calculate the RMSE for the predictions\n",
    "rmse_error = calculate_rmse(df_test.score.values, predicted_scores)\n",
    "\n",
    "# Print the RMSE result\n",
    "print('The out-of-sample RMSE of rating predictions is', round(rmse_error, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
